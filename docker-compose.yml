networks:
  lsdm-net:
    driver: bridge

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    networks:
      - lsdm-net

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    expose:
      - "29092"
    environment:
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 #!
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 #!
      - KAFKA_DEFAULT_REPLICATION_FACTOR=1 #!
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_MIN_INSYNC_REPLICAS=1
    volumes:
      - ./kafka/kafka-entrypoint.sh:/kafka-entrypoint.sh:ro
    command: ["/kafka-entrypoint.sh"]
    networks:
      - lsdm-net
    deploy:
      replicas: 1 # Number of Kafka brokers

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    ports:
      - "8081:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka
    networks:
      - lsdm-net

  spark-master:
    image: apache/spark:3.4.3-scala2.12-java11-python3-ubuntu
    command: bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - lsdm-net

  spark-worker:
    image: apache/spark:3.4.3-scala2.12-java11-python3-ubuntu
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    networks:
      - lsdm-net
    deploy:
      replicas: 2

  client-app:
    build:
      context: .
      dockerfile: app-base.Dockerfile
    container_name: client-app
    depends_on:
      - kafka
      - elasticsearch
    volumes:
      - ./app:/workspace/app
    working_dir: /workspace/app
    command: >
      sh -c "pip install -r requirements.txt && tail -f /dev/null"
    environment:
      - KAFKA_BROKER=kafka:29092
      - TOPIC_NAME=cluster-metrics
    networks:
      - lsdm-net

  elasticsearch:
    image: elasticsearch:8.8.2
    ports:
      - "9200:9200"
    environment:
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - cluster.name=docker-cluster
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data
    networks:
      - lsdm-net

  kibana:
    image: kibana:8.8.2
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - XPACK_SECURITY_ENABLED=false
    depends_on:
      - elasticsearch
    volumes:
      - ./kibana/data:/usr/share/kibana/data
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    networks:
      - lsdm-net